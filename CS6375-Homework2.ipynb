{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WCa7seky2YDr"
   },
   "source": [
    "### <font color='#cb4154'> CS6375: Machine Learning (Spring '19) </font>\n",
    "_**Instructor**: Gautam Kunapuli_ <br>\n",
    "_**Due**: In class, **February 27 (Wednesday)**_\n",
    "\n",
    "---\n",
    "\n",
    "# **_Homework 2_**\n",
    "\n",
    "The report component of this assignment is the **hard copy** of this homework, along with your answers to questions, and is **due at the start of class on <font color='#cb4154'>Wednesday, February 27, 2019</font>**.\n",
    "\n",
    "The **electronic version** of this homework **must be uploaded on eLearning by <font color='#cb4154'>12:59pm Central Standard Time, Wednesday, February 27, 2019</font>**. All deadlines are hard and without exceptions unless permission was obtained from the instructor **in advance**. \n",
    "\n",
    "You may work in groups to discuss the problems and work through solutions together. However, you must **write up your solutions on your own**, without copying another student's work or letting another student copy your work. In your solution for each problem, you must write down the names of your partner (if any); this will not affect your grade. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "198ZoDEZ3FtN"
   },
   "source": [
    "# 1. <font color='#cb4154'> **Support Vector Machines with Synthetic Data**</font>, 50 points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ewqefiUP3p7a"
   },
   "source": [
    "For this problem, we will generate synthetic data for a nonlinear binary classification problem and partition it into training, validation and test sets. Our goal is to understand the behavior of SVMs with Radial-Basis Function (RBF) kernels with different values of $C$ and $\\gamma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LhGIqSvX1_Sl"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# DO NOT EDIT THIS FUNCTION; IF YOU WANT TO PLAY AROUND WITH DATA GENERATION, \n",
    "# MAKE A COPY OF THIS FUNCTION AND THEN EDIT\n",
    "#\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "def generate_data(n_samples, tst_frac=0.2, val_frac=0.2):\n",
    "  # Generate a non-linear data set\n",
    "  X, y = make_moons(n_samples=n_samples, noise=0.25, random_state=42)\n",
    "   \n",
    "  # Take a small subset of the data and make it VERY noisy; that is, generate outliers\n",
    "  m = 30\n",
    "  np.random.seed(42)\n",
    "  ind = np.random.permutation(n_samples)[:m]\n",
    "  X[ind, :] += np.random.multivariate_normal([0, 0], np.eye(2), (m, ))\n",
    "  y[ind] = 1 - y[ind]\n",
    "\n",
    "  # Plot this data\n",
    "  cmap = ListedColormap(['#b30065', '#178000'])\n",
    "  plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap, edgecolors='k')       \n",
    "  \n",
    "  # First, we use train_test_split to partition (X, y) into training and test sets\n",
    "  X_trn, X_tst, y_trn, y_tst = train_test_split(X, y, test_size=tst_frac, \n",
    "                                                random_state=42)\n",
    "\n",
    "  # Next, we use train_test_split to further partition (X_trn, y_trn) into training and validation sets\n",
    "  X_trn, X_val, y_trn, y_val = train_test_split(X_trn, y_trn, test_size=val_frac, \n",
    "                                                random_state=42)\n",
    "  \n",
    "  return (X_trn, y_trn), (X_val, y_val), (X_tst, y_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j1CeM8EK4QHj"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#  DO NOT EDIT THIS FUNCTION; IF YOU WANT TO PLAY AROUND WITH VISUALIZATION, \n",
    "#  MAKE A COPY OF THIS FUNCTION AND THEN EDIT \n",
    "#\n",
    "\n",
    "def visualize(models, param, X, y):\n",
    "  # Initialize plotting\n",
    "  if len(models) % 3 == 0:\n",
    "    nrows = len(models) // 3\n",
    "  else:\n",
    "    nrows = len(models) // 3 + 1\n",
    "    \n",
    "  fig, axes = plt.subplots(nrows=nrows, ncols=3, figsize=(15, 5.0 * nrows))\n",
    "  cmap = ListedColormap(['#b30065', '#178000'])\n",
    "\n",
    "  # Create a mesh\n",
    "  xMin, xMax = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "  yMin, yMax = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "  xMesh, yMesh = np.meshgrid(np.arange(xMin, xMax, 0.01), \n",
    "                             np.arange(yMin, yMax, 0.01))\n",
    "\n",
    "  for i, (p, clf) in enumerate(models.items()):\n",
    "    # if i > 0:\n",
    "    #   break\n",
    "    r, c = np.divmod(i, 3)\n",
    "    ax = axes[r, c]\n",
    "\n",
    "    # Plot contours\n",
    "    zMesh = clf.decision_function(np.c_[xMesh.ravel(), yMesh.ravel()])\n",
    "    zMesh = zMesh.reshape(xMesh.shape)\n",
    "    ax.contourf(xMesh, yMesh, zMesh, cmap=plt.cm.PiYG, alpha=0.6)\n",
    "\n",
    "    if (param == 'C' and p > 0.0) or (param == 'gamma'):\n",
    "      ax.contour(xMesh, yMesh, zMesh, colors='k', levels=[-1, 0, 1], \n",
    "                 alpha=0.5, linestyles=['--', '-', '--'])\n",
    "\n",
    "    # Plot data\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap, edgecolors='k')       \n",
    "    ax.set_title('{0} = {1}'.format(param, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2vksl6V4YQ1"
   },
   "outputs": [],
   "source": [
    "# Generate the data\n",
    "n_samples = 300    # Total size of data set \n",
    "(X_trn, y_trn), (X_val, y_val), (X_tst, y_tst) = generate_data(n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-0stHFSe4fnH"
   },
   "source": [
    "---\n",
    "### **a**. (25 points)  The effect of the regularization parameter, $C$\n",
    "Complete the Python code snippet below that takes the generated synthetic 2-d data as input and learns non-linear SVMs. Use scikit-learn's [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) function to learn SVM models with **radial-basis kernels** for fixed $\\gamma$ and various choices of $C \\in \\{10^{-3}, 10^{-2}\\, \\cdots, 1, \\, \\cdots\\, 10^5\\}$. The value of $\\gamma$ is fixed to $\\gamma = \\frac{1}{d \\cdot \\sigma_X}$, where $d$ is the data dimension and $\\sigma_X$ is the standard deviation of the data set $X$. SVC can automatically use these setting for $\\gamma$ if you pass the argument gamma = 'scale' (see documentation for more details).\n",
    "\n",
    "**Plot**: For each classifier, compute **both** the **training error** and the **validation error**. Plot them together, making sure to label the axes and each curve clearly.\n",
    "\n",
    "**Discussion**: How do the training error and the validation error change with $C$? Based on the visualization of the models and their resulting classifiers, how does changing $C$ change the models? Explain in terms of minimizing the SVM's objective function $\\frac{1}{2} \\mathbf{w}^\\prime \\mathbf{w} \\, + \\, C \\, \\Sigma_{i=1}^n \\, \\ell(\\mathbf{w} \\mid \\mathbf{x}_i, y_i)$, where $\\ell$ is the hinge loss for each training example $(\\mathbf{x}_i, y_i)$.\n",
    "\n",
    "**Final Model Selection**: Use the validation set to select the best the classifier corresponding to the best value, $C_{best}$. Report the accuracy on the **test set** for this selected best SVM model. _Note: You should report a single number, your final test set accuracy on the model corresponding to $C_{best}$_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t63YP-bJ4hzJ"
   },
   "outputs": [],
   "source": [
    "# Learn support vector classifiers with a radial-basis function kernel with \n",
    "# fixed gamma = 1 / (n_features * X.std()) and different values of C\n",
    "C_range = np.arange(-3.0, 6.0, 1.0)\n",
    "C_values = np.power(10.0, C_range)\n",
    "\n",
    "models = dict()\n",
    "trnErr = dict()\n",
    "valErr = dict()\n",
    "\n",
    "for C in C_values:\n",
    "  #\n",
    "  #\n",
    "  # Insert your code here to learn SVM models\n",
    "  #\n",
    "  #\n",
    "  \n",
    "visualize(models, 'C', X_trn, y_trn)\n",
    "\n",
    "#\n",
    "#\n",
    "# Insert your code here to perform model selection\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "evEeXgSE9Hss"
   },
   "source": [
    "---\n",
    "### **b**. (25 points)  The effect of the RBF kernel parameter, $\\gamma$\n",
    "Complete the Python code snippet below that takes the generated synthetic 2-d data as input and learns various non-linear SVMs. Use scikit-learn's [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) function to learn SVM models with **radial-basis kernels** for fixed $C$ and various choices of $\\gamma \\in \\{10^{-2}, 10^{-1}\\, 1, 10, \\, 10^2 \\, 10^3\\}$. The value of $C$ is fixed to $C = 10$.\n",
    "\n",
    "**Plot**: For each classifier, compute **both** the **training error** and the **validation error**. Plot them together, making sure to label the axes and each curve clearly.\n",
    "\n",
    "**Discussion**: How do the training error and the validation error change with $\\gamma$? Based on the visualization of the models and their resulting classifiers, how does changing $\\gamma$ change the models? Explain in terms of the functional form of the RBF kernel, $\\kappa(\\mathbf{x}, \\,\\mathbf{z}) \\, = \\, \\exp(-\\gamma \\cdot \\|\\mathbf{x} - \\mathbf{z} \\|^2)$\n",
    "\n",
    "**Final Model Selection**: Use the validation set to select the best the classifier corresponding to the best value, $\\gamma_{best}$. Report the accuracy on the **test set** for this selected best SVM model. _Note: You should report a single number, your final test set accuracy on the model corresponding to $\\gamma_{best}$_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QYzLo_zv-bIk"
   },
   "outputs": [],
   "source": [
    "# Learn support vector classifiers with a radial-basis function kernel with \n",
    "# fixed C = 10.0 and different values of gamma\n",
    "gamma_range = np.arange(-2.0, 4.0, 1.0)\n",
    "gamma_values = np.power(10.0, gamma_range)\n",
    "\n",
    "models = dict()\n",
    "trnErr = dict()\n",
    "valErr = dict()\n",
    "\n",
    "for G in gamma_values:\n",
    "  #\n",
    "  #\n",
    "  # Insert your code here to learn SVM models\n",
    "  #\n",
    "  #\n",
    "  \n",
    "visualize(models, 'gamma', X_trn, y_trn)\n",
    "\n",
    "#\n",
    "#\n",
    "# Insert your code here to perform model selection\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7K44mi5_3LrL"
   },
   "source": [
    "---\n",
    "# 2. <font color='#cb4154'> **Breast Cancer Diagnosis with Support Vector Machines**</font>, 25 points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PAwcBYkQ_KdK"
   },
   "source": [
    "For this problem, we will use the [Wisconsin Breast Cancer](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)) data set, which has already been pre-processed and partitioned into training, validation and test sets. Numpy's [loadtxt](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.loadtxt.html) command can be used to load CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zrb6AvCJ_WYX"
   },
   "outputs": [],
   "source": [
    "# Load the Breast Cancer Diagnosis data set; download the files from eLearning\n",
    "# CSV files can be read easily using np.loadtxt()\n",
    "#\n",
    "# Insert your code here.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h0VvyMt3AAZQ"
   },
   "source": [
    "Use scikit-learn's [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) function to learn SVM models with **radial-basis kernels** for **each combination** of $C \\in \\{10^{-2}, 10^{-1}, 1, 10^1, \\, \\cdots\\, 10^4\\}$ and $\\gamma \\in \\{10^{-3}, 10^{-2}\\, 10^{-1}, 1, \\, 10, \\, 10^2\\}$. Print the tables corresponding to the training and validation errors.\n",
    "\n",
    "**Final Model Selection**: Use the validation set to select the best the classifier corresponding to the best parameter values, $C_{best}$ and $\\gamma_{best}$. Report the accuracy on the **test set** for this selected best SVM model. _Note: You should report a single number, your final test set accuracy on the model corresponding to $C_{best}$ and $\\gamma_{best}$_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qPjbglVuBYt3"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# Insert your code here to perform model selection\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. <font color='#cb4154'> **Decision Trees**</font>, 25 points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. (12 points)  Interpreting a Decision Tree (Pencil and Paper)\n",
    "\n",
    "Consider the decision boundary in the figure below and draw the equivalent decision tree. Red circles are Class +1 and blue squares, Class -1.\n",
    "\n",
    "![If the figure is not visible, make sure you have placed the file HW02_DecisionTrees_3a.png in the same directory as this Python notebook.](./HW02_DecisionTrees_3a.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. (13 points)  Visualizing a Decision Tree (Pencil and Paper)\n",
    "\n",
    "Consider the decision tree in the figure below and draw the equivalent decision boundary. Make sure to label each decision region with the corresponding leaf node from the decision tree.\n",
    "\n",
    "![If the figure is not visible, make sure you have placed the file HW02_DecisionTrees_3b.png in the same directory as this Python notebook.](./HW02_DecisionTrees_3b.png)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CS6301-Homework2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
